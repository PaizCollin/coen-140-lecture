{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Classification using k-mer frequency representation of text\n",
    "\n",
    "In this project, we will create a program to transform text into vectors using a slightly different technique than previously learned, and then perform kNN based classification on the resulting vectors. We will be using the badges UCI dataset (https://archive.ics.uci.edu/ml/machine-learning-databases/badges/badges.data), which contains names of some conference attendees along with a \"+\" or \"-\" class for each name. We will first make the text lowercase and separate the class from the badge name for each object, e.g., \"+ Naoki Abe\" should be turned into the object \"naoki abe\" with class \"+\". We will keep track of the original name (\"Naoki Abe\") associated with the vector.\n",
    "\n",
    "Our program will have two input parameters, c and k. Given the input parameter c, for each name, it will construct a vector of c-mer terms (usually called k-mers, but I am calling them c-mers since the input variable k is being used for kNN) of the required c length, by enumerating all subsequences of length c within the name. For example, if c=3, “naoki abe” becomes < “nao”, “aok”, “oki”, “ki “, “i a”, “ ab”, “abe” >. Finally, we will use the same technique we learned for word-based terms to construct sparse term-frequency vectors for each of the objects.\n",
    "\n",
    "Using the constructed vectors and their associated classes, given the input parameter k, we will construct a program that should perform kNN based classification using cosine similarity and 10-fold cross-validation and report the average classification accuracy among all tests. The class of the test sample should be chosen by majority vote, with ties broken in favor of the class with the highest average similarity. In the rare case that the test sample does not have any neighbors (no features in common with any training samples), we will assign a predicted class label by drawing a random value from a uniform distribution over [0,1) and classifying the test sample as “+” if the value is greater than 0.5 and “-“ otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reads the badges dataset into the variable `df` and extracts the string data associated with each person in the `vals` variable. Write code to split the strings in vals into their component names and classes. The `names` and `cls` lists should hold those components such that the $i$th person's name will be in `names[i]` and their associated class in `cls[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "df = pd.read_csv(\n",
    "    'train_copy.dat', \n",
    "     sep='delimiter', header=None, engine ='python')\n",
    "\n",
    "# separate names from classes\n",
    "vals = df.iloc[:,:].values\n",
    "names = [n[0][2:] for n in vals]\n",
    "cls = [n[0][0] for n in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that, given a name and a `c-mer` length parameter `c`, will create the list of `c-mers` for the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmer(name, c=3):\n",
    "    r\"\"\" Given a name and parameter c, return the vector of c-mers associated with the name\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    if len(name) < c:\n",
    "        return [name]\n",
    "    v = []\n",
    "    for i in range(len(name)-c+1):\n",
    "        v.append(name[i:(i+c)])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will be useful in later tasks. Study them carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int_)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int_)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n",
    "        \n",
    "def namesToMatrix(names, c):\n",
    "    docs = [cmer(n, c) for n in names]\n",
    "    return build_matrix(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the sparse matrix statistics (via `csr_info`) for c-mer representations of the names given $c\\in\\{1,2,3\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 2000, ncols 56, nnz 58157]\n",
      " [nrows 2000, ncols 1499, nnz 254623]\n",
      " [nrows 2000, ncols 11251, nnz 374726]\n"
     ]
    }
   ],
   "source": [
    "csr_info(namesToMatrix(names, 1))\n",
    "csr_info(namesToMatrix(names, 2))\n",
    "csr_info(namesToMatrix(names, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define a function to search for the top-$k$ neighbors for a given name (one of the objects the dataset), where proximity is computed via cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNeighborsForName(name, c=1, k=1):\n",
    "    # first, find the document for the given name\n",
    "    id = -1\n",
    "    for i in range(len(names)):\n",
    "        if names[i] == name:\n",
    "            id = i\n",
    "            break\n",
    "    if id == -1:\n",
    "        print(\"Name %s not found.\" % name)\n",
    "        return []\n",
    "    # now, compute similarities of name's vector against all other name vectors\n",
    "    mat = namesToMatrix(names, c)\n",
    "    csr_l2normalize(mat)\n",
    "    x = mat[id,:]\n",
    "    dots = x.dot(mat.T)\n",
    "    dots[0,id] = -1 # invalidate self-similarity\n",
    "    sims = list(zip(dots.indices, dots.data))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [names[s[0]] for s in sims[:k] if s[1] > 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let c=2 and k=5. Which are the closest neighbors for “Michael Kearns”, in decreasing order of similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Michael Kearns not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNeighborsForName(\"Michael Kearns\", c=2, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define a couple functions to perform $d$-fold cross-validation, defaulting to $d=10$. Double-check the code for errors. What does the line\n",
    "```python\n",
    "tc = Counter(clstr[s[0]] for s in sims[:k]).most_common(2)\n",
    "```\n",
    "do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(mat, cls, fold=1, d=10):\n",
    "    r\"\"\" Split the matrix and class info into train and test data using d-fold hold-out\n",
    "    \"\"\"\n",
    "    n = mat.shape[0]\n",
    "    r = int(np.ceil(n*1.0/d))\n",
    "    mattr = []\n",
    "    clstr = []\n",
    "    # split mat and cls into d folds\n",
    "    for f in range(d):\n",
    "        if f+1 != fold:\n",
    "            mattr.append( mat[f*r: min((f+1)*r, n)] )\n",
    "            clstr.extend( cls[f*r: min((f+1)*r, n)] )\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(mattr, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = mat[(fold-1)*r: min(fold*r, n), :]\n",
    "    clste = cls[(fold-1)*r: min(fold*r, n)]\n",
    "\n",
    "    return train, clstr, test, clste\n",
    "    \n",
    "def classifyNames(names, cls, c=3, k=3, d=10):\n",
    "    r\"\"\" Classify names using c-mer frequency vector representations of the names and kNN classification with \n",
    "    cosine similarity and 10-fold cross validation\n",
    "    \"\"\"\n",
    "    docs = [cmer(n, c) for n in names]\n",
    "    mat = build_matrix(docs)\n",
    "    # since we're using cosine similarity, normalize the vectors\n",
    "    csr_l2normalize(mat)\n",
    "    \n",
    "    def classify(x, train, clstr, k):\n",
    "        r\"\"\" Classify vector x using kNN and majority vote rule given training data and associated classes\n",
    "        \"\"\"\n",
    "        # find nearest neighbors for x\n",
    "        dots = x.dot(train.T)\n",
    "        sims = list(zip(dots.indices, dots.data))\n",
    "        if len(sims) == 0:\n",
    "            # could not find any neighbors\n",
    "            return '+' if np.random.rand() > 0.5 else '-'\n",
    "        sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        tc = Counter(clstr[s[0]] for s in sims[:k]).most_common(2)\n",
    "        if len(tc) < 2 or tc[0][1] > tc[1][1]:\n",
    "            # majority vote\n",
    "            return tc[0][0]\n",
    "        # tie break\n",
    "        tc = defaultdict(float)\n",
    "        for s in sims[:k]:\n",
    "            tc[clstr[s[0]]] += s[1]\n",
    "        return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        \n",
    "    macc = 0.0\n",
    "    for f in range(d):\n",
    "        # split data into training and testing\n",
    "        train, clstr, test, clste = splitData(mat, cls, f+1, d)\n",
    "        # predict the class of each test sample\n",
    "        clspr = [ classify(test[i,:], train, clstr, k) for i in range(test.shape[0]) ]\n",
    "        # compute the accuracy of the prediction\n",
    "        acc = 0.0\n",
    "        for i in range(len(clste)):\n",
    "            if clste[i] == clspr[i]:\n",
    "                acc += 1\n",
    "        acc /= len(clste)\n",
    "        macc += acc\n",
    "        \n",
    "    return macc/d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $c \\in \\{1,\\ldots,4\\}$ and  $k \\in \\{1,\\ldots,6\\}$, which meta-parameters result in the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=1, k=1, 0.354500\n",
      "c=1, k=2, 0.354500\n",
      "c=1, k=3, 0.383500\n",
      "c=1, k=4, 0.389000\n",
      "c=1, k=5, 0.402500\n",
      "c=1, k=6, 0.404500\n",
      "c=1, k=7, 0.411500\n",
      "c=1, k=8, 0.411000\n",
      "c=1, k=9, 0.424000\n",
      "c=2, k=1, 0.537000\n",
      "c=2, k=2, 0.537000\n",
      "c=2, k=3, 0.548000\n",
      "c=2, k=4, 0.558000\n",
      "c=2, k=5, 0.563000\n",
      "c=2, k=6, 0.572000\n",
      "c=2, k=7, 0.581000\n",
      "c=2, k=8, 0.580000\n",
      "c=2, k=9, 0.584500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         macc \u001b[39m=\u001b[39m classifyNames(names, \u001b[39mcls\u001b[39;49m, c\u001b[39m=\u001b[39;49mc, k\u001b[39m=\u001b[39;49mk)\n\u001b[0;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mc=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, k=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (c, k, macc))\n\u001b[0;32m      6\u001b[0m         \u001b[39mif\u001b[39;00m macc \u001b[39m>\u001b[39m best[\u001b[39m2\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[46], line 55\u001b[0m, in \u001b[0;36mclassifyNames\u001b[1;34m(names, cls, c, k, d)\u001b[0m\n\u001b[0;32m     53\u001b[0m train, clstr, test, clste \u001b[39m=\u001b[39m splitData(mat, \u001b[39mcls\u001b[39m, f\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, d)\n\u001b[0;32m     54\u001b[0m \u001b[39m# predict the class of each test sample\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m clspr \u001b[39m=\u001b[39m [ classify(test[i,:], train, clstr, k) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) ]\n\u001b[0;32m     56\u001b[0m \u001b[39m# compute the accuracy of the prediction\u001b[39;00m\n\u001b[0;32m     57\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[46], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m train, clstr, test, clste \u001b[39m=\u001b[39m splitData(mat, \u001b[39mcls\u001b[39m, f\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, d)\n\u001b[0;32m     54\u001b[0m \u001b[39m# predict the class of each test sample\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m clspr \u001b[39m=\u001b[39m [ classify(test[i,:], train, clstr, k) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) ]\n\u001b[0;32m     56\u001b[0m \u001b[39m# compute the accuracy of the prediction\u001b[39;00m\n\u001b[0;32m     57\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[46], line 34\u001b[0m, in \u001b[0;36mclassifyNames.<locals>.classify\u001b[1;34m(x, train, clstr, k)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\" Classify vector x using kNN and majority vote rule given training data and associated classes\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# find nearest neighbors for x\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m dots \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(train\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m     35\u001b[0m sims \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(dots\u001b[39m.\u001b[39mindices, dots\u001b[39m.\u001b[39mdata))\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sims) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     37\u001b[0m     \u001b[39m# could not find any neighbors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:416\u001b[0m, in \u001b[0;36mspmatrix.dot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m \u001b[39m*\u001b[39m other\n\u001b[0;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m \u001b[39m@\u001b[39;49m other\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_dispatch(other)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m other\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m    540\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdimension mismatch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_sparse_matrix(other)\n\u001b[0;32m    543\u001b[0m \u001b[39m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    544\u001b[0m other_a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_compressed.py:518\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    514\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices,\n\u001b[0;32m    515\u001b[0m                              other\u001b[39m.\u001b[39mindptr, other\u001b[39m.\u001b[39mindices))\n\u001b[0;32m    517\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matmat_maxnnz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 518\u001b[0m nnz \u001b[39m=\u001b[39m fn(M, N,\n\u001b[0;32m    519\u001b[0m          np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[0;32m    520\u001b[0m          np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[0;32m    521\u001b[0m          np\u001b[39m.\u001b[39;49masarray(other\u001b[39m.\u001b[39;49mindptr, dtype\u001b[39m=\u001b[39;49midx_dtype),\n\u001b[0;32m    522\u001b[0m          np\u001b[39m.\u001b[39;49masarray(other\u001b[39m.\u001b[39;49mindices, dtype\u001b[39m=\u001b[39;49midx_dtype))\n\u001b[0;32m    524\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices,\n\u001b[0;32m    525\u001b[0m                              other\u001b[39m.\u001b[39mindptr, other\u001b[39m.\u001b[39mindices),\n\u001b[0;32m    526\u001b[0m                             maxval\u001b[39m=\u001b[39mnnz)\n\u001b[0;32m    528\u001b[0m indptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(major_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39midx_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = (0.0, 0.0, 0.0)\n",
    "for c in range(1,10):\n",
    "    for k in range(1, 10):\n",
    "        macc = classifyNames(names, cls, c=c, k=k)\n",
    "        print(\"c=%d, k=%d, %f\" % (c, k, macc))\n",
    "        if macc > best[2]:\n",
    "            best = (c, k, macc)\n",
    "print(\"Best: c=%d, k=%d, %f\" % best)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
