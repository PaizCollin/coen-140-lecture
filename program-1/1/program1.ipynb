{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# read in the dataset\n",
    "train = pd.read_csv(\n",
    "    'train.dat', \n",
    "     sep='delimiter', header=None, engine ='python')\n",
    "\n",
    "test = pd.read_csv(\n",
    "    'test.dat', \n",
    "     sep='delimiter', header=None, engine ='python')\n",
    "\n",
    "# separate names from classes\n",
    "train_vals = train.iloc[:,:].values\n",
    "train_docs = [n[0][2:] for n in train_vals]\n",
    "train_cls = [n[0][0] for n in train_vals]\n",
    "\n",
    "test_vals = test.iloc[:,:].values\n",
    "test_docs = [n[0][0:] for n in test_vals]\n",
    "test_cls = [] * len(test_docs)\n",
    "\n",
    "# corpus = pd.DataFrame({'doc': train_docs, 'class': train_cls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmer(doc, c=3):\n",
    "    r\"\"\" Given a name and parameter c, return the vector of c-mers associated with the doc\n",
    "    \"\"\"\n",
    "    doc = doc.lower()\n",
    "    if len(doc) < c:\n",
    "        return [doc]\n",
    "    v = []\n",
    "    for i in range(len(doc)-c+1):\n",
    "        v.append(doc[i:(i+c)])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(docs, idx):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(list(w for w in d if w in idx))\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common() if k in idx)\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            if k in idx:\n",
    "                ind[j+n] = idx[k]\n",
    "                val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n",
    "    \n",
    "def build_idx(train_mat):\n",
    "    r\"\"\" Build a mapping from word to ID and vice versa. \n",
    "    \"\"\"\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    for d in train_mat:\n",
    "        for w in d:\n",
    "            w.lower()\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    return idx\n",
    "    \n",
    "    #get rid of build both, just idx of train set!!\n",
    "def textToMatrix(train_docs, test_docs, c=3):\n",
    "    train_mat = [cmer(l,c) for l in train_docs]\n",
    "    test_mat = [cmer(l,c) for l in test_docs]\n",
    "    return train_mat, test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mat [nrows 102080, ncols 1335522, nnz 22120884]\n",
      "test_mat [nrows 25520, ncols 1335522, nnz 5379210]\n"
     ]
    }
   ],
   "source": [
    "train_mat, test_mat = textToMatrix(train_docs, test_docs, 6)\n",
    "idx = build_idx(train_mat)\n",
    "\n",
    "train_mat = csr_l2normalize(build_matrix(train_mat, idx), copy=True)\n",
    "test_mat = csr_l2normalize(build_matrix(test_mat, idx), copy=True)\n",
    "\n",
    "csr_info(train_mat, \"train_mat\")\n",
    "csr_info(test_mat, \"test_mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x, train, clstr, k=3):\n",
    "    r\"\"\" Classify vector x using kNN and majority vote rule given training data and associated classes\n",
    "    \"\"\"\n",
    "    # find nearest neighbors for x\n",
    "    dots = x.dot(train.T)\n",
    "    sims = list(zip(dots.indices, dots.data))\n",
    "    if len(sims) == 0:\n",
    "        # could not find any neighbors\n",
    "        return '+' if np.random.rand() > 0.5 else '-'\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    tc = Counter(clstr[s[0]] for s in sims[:k]).most_common(2)\n",
    "    if len(tc) < 2 or tc[0][1] > tc[1][1]:\n",
    "        # majority vote\n",
    "        return tc[0][0]\n",
    "    # tie break\n",
    "    tc = defaultdict(float)\n",
    "    for s in sims[:k]:\n",
    "        tc[clstr[s[0]]] += s[1]\n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        1\n",
       "2        1\n",
       "3        3\n",
       "4        4\n",
       "        ..\n",
       "25515    3\n",
       "25516    2\n",
       "25517    1\n",
       "25518    4\n",
       "25519    3\n",
       "Length: 25520, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = open('output.dat', 'w', newline='')\n",
    "test_cls = [ classify(test_mat[i,:], train_mat, train_cls, 9) for i in range(test_mat.shape[0]) ]\n",
    "predictions = pd.Series(test_cls)\n",
    "predictions.to_csv(output_file, index=False, header=None)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaya = open('yaya.dat', 'w+', newline='')\n",
    "predictions.to_csv(yaya, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yayaya.dat', 'w') as f:\n",
    "    for item in test_cls:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
